# Instalacion de Apache Hadoop en Lunix (Ubuntu)

Apache Spark es un motor de análisis unificado para el procesamiento de datos a gran escala. Gracias a su alta velocidad de procesamiento en memoria, la plataforma es popular en entornos de computación distribuida.

Spark admite diversas fuentes y formatos de datos y puede ejecutarse en clústeres independientes o integrarse con Hadoop , Kubernetes y servicios en la nube . Al ser un framework de código abierto , admite diversos lenguajes de programación como Java , Scala, Python y R.

En este tutorial, aprenderá cómo instalar y configurar Hadoop en Ubuntu.

## Pre-Requisitos

- Un sistema Ubuntu.
- Acceso a una terminal o línea de comandos.
- Un usuario con permisos sudo o root.
